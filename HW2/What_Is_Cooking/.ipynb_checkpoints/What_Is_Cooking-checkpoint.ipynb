{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (a): Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AngZhou\\Anaconda3\\envs\\py27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation, naive_bayes , metrics\n",
    "\n",
    "df = pd.read_json('./all/train.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (b): \n",
    "Tell us about the data. How many samples (dishes) are there in the training set? How many categories (types of cuisine)? Use a list to keep all the unique ingredients appearing in the trainingset. How many unique ingredients are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39774"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_obs = df.shape[0]\n",
    "num_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer 1: Total number of the samples is: 39774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'greek' u'southern_us' u'filipino' u'indian' u'jamaican' u'spanish'\n",
      " u'italian' u'mexican' u'chinese' u'british' u'thai' u'vietnamese'\n",
      " u'cajun_creole' u'brazilian' u'french' u'japanese' u'irish' u'korean'\n",
      " u'moroccan' u'russian']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "cuisine_array=df.cuisine.unique()\n",
    "print cuisine_array\n",
    "print cuisine_array.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer 2: There are totally 20 types of cuisines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_collection=df['ingredients'].values\n",
    "# print ingredients_collection\n",
    "\n",
    "ingredients = set()\n",
    "for i in ingredients_collection:\n",
    "    ingredients = ingredients.union(i)\n",
    "    \n",
    "ing_list = list(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6714"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ing_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer 3: There are totally 6714 unique ingredients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (c)\n",
    "Represent each dish by a binary ingredient feature vector. Suppose there are d different ingredients in total from the training set, represent each dish by a 1×d binary ingredient vector x, where xi =1 if the dish contains ingredient i and xi =0 otherwise. For example, suppose all the ingredients we have in the training set are { beef, chicken, egg, lettuce, tomato, rice } and the dish is made by ingredients { chicken, lettuce, tomato, rice }, then the dish could be represented by a 6×1 binary vector [0,1,0,1,1,1] as its feature or attribute. Use n×d feature matrix to represent all the dishes in training set and testset, where n is the number of dishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "(39774L, 6714L)\n",
      "(9944L, 6714L)\n",
      "end\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df2 = pd.read_json('./all/test.json')\n",
    "num_obs2 = df2.shape[0]\n",
    "\n",
    "print 'start'\n",
    "featureList = []\n",
    "\n",
    "for i in range(num_obs): #len(trainData)\n",
    "    feature = [0] * len(ing_list)\n",
    "    sub_list = ingredients_collection[i]\n",
    "    for j in range(len(ing_list)):\n",
    "        if ing_list[j] in sub_list:\n",
    "            #print (\"yes\",ing_list[j],j)\n",
    "            feature[j] = 1\n",
    "    featureList.append(feature)\n",
    "\n",
    "featureMatrix = np.matrix(featureList)\n",
    "print featureMatrix.shape\n",
    "\n",
    "\n",
    "featureList2 = [] ## for test set\n",
    "\n",
    "\n",
    "for i in range(df2.shape[0]): # len(trainData)\n",
    "    feature = [0] * len(ing_list)  # Note here, we still use the ingredient list obtained from training set\n",
    "    sub_list = (df2['ingredients'].values)[i]\n",
    "    for j in range(len(ing_list)):\n",
    "        if ing_list[j] in sub_list:\n",
    "            feature[j] = 1\n",
    "    featureList2.append(feature)\n",
    "\n",
    "featureMatrix2 = np.matrix(featureList2)\n",
    "print featureMatrix2.shape\n",
    "print 'end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print np.sum(featureMatrix[0]) == len(df.ingredients[0])\n",
    "print np.sum(featureMatrix[1]) == len(df.ingredients[1])\n",
    "print np.sum(featureMatrix[2]) == len(df.ingredients[2])\n",
    "print np.sum(featureMatrix[3]) == len(df.ingredients[3])\n",
    "print np.sum(featureMatrix2[0]) == len(df2.ingredients[0])\n",
    "print np.sum(featureMatrix2[1]) == len(df2.ingredients[1])\n",
    "print np.sum(featureMatrix2[2]) == len(df2.ingredients[2])\n",
    "print np.sum(featureMatrix2[3]) == len(df2.ingredients[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer: Above print statements check whether the numbers of the ingredients in featureMatrix match the dataset. And we check the first 4 observations with correct output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (d)\n",
    "Using Naïve Bayes Classiﬁer to perform 3 fold cross-validation on the training set and report your average classiﬁcation accuracy. Try both Gaussian distribution prior assumption and Bernoulli distribution prior assumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold1=list(cross_validation.KFold(num_obs, n_folds=3))[0]\n",
    "fold2=list(cross_validation.KFold(num_obs, n_folds=3))[1]\n",
    "fold3=list(cross_validation.KFold(num_obs, n_folds=3))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_Naive_Bayes_evaluate(dataSet,labels,fold_indices,NB):\n",
    "    train_indices, test_indices = fold_indices\n",
    "    X_train = dataSet[train_indices]\n",
    "    Y_train = labels[train_indices]\n",
    "    X_test = dataSet[test_indices]\n",
    "    Y_test = labels[test_indices]\n",
    "    \n",
    "    if(NB == 'Bernoulli'):\n",
    "        clf = naive_bayes.BernoulliNB()\n",
    "    elif(NB == 'Gaussian'):\n",
    "        clf = naive_bayes.GaussianNB()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    # BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "    Y_estimate = clf.predict(X_test)\n",
    "    return (Y_estimate,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Y_predict,Y_true):\n",
    "    return metrics.accuracy_score(Y_true, Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli\n",
      "0.684190677326897\n",
      "0.6795142555438226\n",
      "0.6869060190073918\n"
     ]
    }
   ],
   "source": [
    "print 'Bernoulli'\n",
    "(Y_predict, Y_true) = cross_validation_Naive_Bayes_evaluate(featureMatrix,df.cuisine,fold1,'Bernoulli')\n",
    "acc1 = accuracy(Y_predict,Y_true)\n",
    "print acc1\n",
    "(Y_predict, Y_true) = cross_validation_Naive_Bayes_evaluate(featureMatrix,df.cuisine,fold2,'Bernoulli')\n",
    "acc2 = accuracy(Y_predict,Y_true)\n",
    "print acc2\n",
    "(Y_predict, Y_true) = cross_validation_Naive_Bayes_evaluate(featureMatrix,df.cuisine,fold3,'Bernoulli')\n",
    "acc3 = accuracy(Y_predict,Y_true)\n",
    "print acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6835369839593705"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc1+acc2+acc3)/3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer: The above is the three accuracy gained by three fold cross validation based on Bernoulli Naive Bayes Classifier. The average accuracy is 0.6835369839593705."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian\n",
      "0.37901644290239855\n",
      "0.3829386031075577\n",
      "0.37758334590435966\n"
     ]
    }
   ],
   "source": [
    "print 'Gaussian'\n",
    "(Y_predict, Y_true) = cross_validation_Naive_Bayes_evaluate(featureMatrix,df.cuisine,fold1,'Gaussian')\n",
    "acc1 = accuracy(Y_predict,Y_true)\n",
    "print acc1\n",
    "(Y_predict, Y_true) = cross_validation_Naive_Bayes_evaluate(featureMatrix,df.cuisine,fold2,'Gaussian')\n",
    "acc2 = accuracy(Y_predict,Y_true)\n",
    "print acc2\n",
    "(Y_predict, Y_true) = cross_validation_Naive_Bayes_evaluate(featureMatrix,df.cuisine,fold3,'Gaussian')\n",
    "acc3 = accuracy(Y_predict,Y_true)\n",
    "print acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3798461306381053"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc1+acc2+acc3)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer: The above is the three accuracy gained by three fold cross validation based on Gaussian Naive Bayes Classifier. The average accuracy is 0.3798461306381053."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (e)\n",
    "For Gaussian prior and Bernoulli prior, which performs better in terms of cross-validation accuracy? Why? Please give speciﬁc arguments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer: Bernoulli prior is much better than the Gaussian prior in terms of cross-validation accuracy. The reason is that the vector of each feature is a binary vector. Gaussian prior works better when the values of feature are continuous values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (f)\n",
    "Using Logistic Regression Model to perform 3 fold cross-validation on the training set and report your average classiﬁcation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_Logistic_Regression_evaluate(dataSet,labels,fold_indices):\n",
    "    train_indices, test_indices = fold_indices\n",
    "    X_train = dataSet[train_indices]\n",
    "    Y_train = labels[train_indices]\n",
    "    X_test = dataSet[test_indices]\n",
    "    Y_test = labels[test_indices]\n",
    "        \n",
    "    clf = LogisticRegression(multi_class='ovr')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_estimate = clf.predict(X_test)\n",
    "    return (Y_estimate,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "0.7758334590435964\n",
      "0.7721375773118118\n",
      "0.7786996530396741\n"
     ]
    }
   ],
   "source": [
    "print 'Logistic Regression'\n",
    "(Y_predict, Y_true) = cross_validation_Logistic_Regression_evaluate(featureMatrix,df.cuisine,fold1)\n",
    "acc1 = accuracy(Y_predict,Y_true)\n",
    "print acc1\n",
    "(Y_predict, Y_true) = cross_validation_Logistic_Regression_evaluate(featureMatrix,df.cuisine,fold2)\n",
    "acc2 = accuracy(Y_predict,Y_true)\n",
    "print acc2\n",
    "(Y_predict, Y_true) = cross_validation_Logistic_Regression_evaluate(featureMatrix,df.cuisine,fold3)\n",
    "acc3 = accuracy(Y_predict,Y_true)\n",
    "print acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7755568964650275"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc1+acc2+acc3)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Answer: The above is the three accuracy gained by three fold cross validation based on Logistic Regression Classifier. The average accuracy is 0.7755568964650275."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question (g)\n",
    "Train your best-performed classiﬁer with all of the training data, and generate test labels on testset. Submit your results to Kaggle and report the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start:\n",
    "Based on previous 3-fold cross validation. The best-performed classiﬁer is logistic regression classifier. We should use logistic regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: reading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_json('./all/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: extract the ingredients features based on the ingredients list we got from training data. Following the same process we did for training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "(9944L, 6714L)\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "print 'start'\n",
    "featureList2 = []\n",
    "\n",
    "for i in range(df2.shape[0]): #len(trainData)\n",
    "    feature = [0] * len(ing_list)\n",
    "    sub_list = (df2['ingredients'].values)[i]\n",
    "    for j in range(len(ing_list)):\n",
    "        if ing_list[j] in sub_list:\n",
    "            feature[j] = 1\n",
    "    featureList2.append(feature)\n",
    "\n",
    "featureMatrix2 = np.matrix(featureList2)\n",
    "print featureMatrix2.shape\n",
    "print 'end'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: build logistic regression model on training set, then apply estimation on testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(multi_class='ovr')\n",
    "clf.fit(featureMatrix, df.cuisine)\n",
    "Y_estimate = clf.predict(featureMatrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: output the estimation and construct the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Output the solution\n",
    "import csv\n",
    "\n",
    "file_name = \"submission.csv\"\n",
    "with open(file_name, mode='wb') as submission_file:\n",
    "    fieldnames = ['id', 'cuisine']\n",
    "    writer = csv.DictWriter(submission_file, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writerow({'id': 'id', 'cuisine': 'cuisine'})\n",
    "    for i in range(len(Y_estimate)):\n",
    "        writer.writerow({'id': df2['id'][i], 'cuisine': Y_estimate[i]})\n",
    "    \n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Whole Problem Finished"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
